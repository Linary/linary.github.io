<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[分布式存储系统]]></title>
    <url>%2F2018%2F08%2F06%2Fdistributed-storage%2F</url>
    <content type="text"><![CDATA[需要调研的分布式存储系统包括但不限于： 谷歌的GFS、BigTable、MegaStore和Spanner，阿里的TFS、Tair和OceanBase，Facebook的Haystack，亚马逊的Dynamo，Oracle的Mysql Sharding，PingCap 的TiDB等。]]></content>
      <categories>
        <category>分布式存储系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[内存数据库事务]]></title>
    <url>%2F2018%2F08%2F06%2Fmemory-db%2F</url>
    <content type="text"><![CDATA[前言 我们在使用数据库的时候，应该都体验过事务，我们对事务最直观的感受就是：一系列的操作要么全部生效，要么全部不生效，不会最后处于一种中间状态。其实这句话似乎只能体现事务的原子性，那其他几个特性呢？本文会先回顾一下事务的定义和ACID特性，再以一个具体的例子展示如何实现事务的四个特性。 事务定义所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 特性 原子性（Atomicity）：事务是一个不可再分割的工作单位，事务中的操作要么都发生，要么都不发生； 一致性（Consistency）：事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。 隔离性（Isolation）：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。 持久性（Durability）：事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava Futures异步回调机制源码解析]]></title>
    <url>%2F2018%2F07%2F23%2Fguava-future%2F</url>
    <content type="text"><![CDATA[前言 最近本人在实现一个异步任务调度框架，不打算依赖于任何第三方包。在实现任务状态监听时遇到了一些困惑，于是想了解一下Guava中的ListenableFuture的实现方式。ListenableFuture实现非阻塞的方式是其提供了回调机制(机制)，下面将阐述该回调机制的实现，主要对Futures的addCallback方法源码进行剖析。 Guava Futures简介Google Guava框架的 com.google.common.util.concurrent包是并发相关的包，它是对JDK自带concurrent包中Future和线程池相关类的扩展，从而衍生出一些新类，并提供了更为广泛的功能。在项目中常用的该包中类如下所示： ListenableFuture：该接口扩展了Future接口，增加了addListener方法，该方法在给定的excutor上注册一个监听器，当计算完成时会马上调用该监听器。不能够确保监听器执行的顺序，但可以在计算完成时确保马上被调用。 FutureCallback：该接口提供了OnSuccess和onFailure方法。获取异步计算的结果并回调。 MoreExecutors：该类是final类型的工具类，提供了很多静态方法。例如listeningDecorator方法初始化ListeningExecutorService方法，使用此实例submit方法即可初始化ListenableFuture对象。 ListenableFutureTask：该类是一个适配器，可以将其它Future适配成ListenableFuture。 ListeningExecutorService：该类是对ExecutorService的扩展，重写了ExecutorService类中的submit方法，并返回ListenableFuture对象。 JdkFutureAdapters：该类扩展了FutureTask类并实现ListenableFuture接口，增加了addListener方法。 Futures：该类提供和很多实用的静态方法以供使用。 Futures.addCallback方法源码剖析下面将模拟异步发送请求，并对请求结果进行(回调)监听。这里使用Spring框架提供的AsyncRestTemplate，来发送http请求，并获取一个org.springframework.util.concurrent.ListenableFuture对象，此时的对象是spring框架中的ListenableFuture对象。由于org.springframework.util.concurrent包中只提供了最基本的监听功能，没有其它额外功能，这里将其转化成Guava中的ListenableFuture，用到了JdkFutureAdapters这个适配器类。(以下源码来自guava-18.0.jar) 12345678910111213141516AsyncRestTemplate tp = new AsyncRestTemplate();org.springframework.util.concurrent.ListenableFuture&lt;ResponseEntity&lt;Object&gt;&gt; response = tp .getForEntity("http://blog.csdn.net/pistolove", Object.class);ListenableFuture&lt;ResponseEntity&lt;Object&gt;&gt; listenInPoolThread = JdkFutureAdapters.listenInPoolThread(response);Futures.addCallback(listenInPoolThread, new FutureCallback&lt;Object&gt;() &#123; @Override public void onSuccess(Object result) &#123; System.err.println(result.getClass()); System.err.printf("success", result); &#125; @Override public void onFailure(Throwable t) &#123; System.out.printf("failure"); &#125;&#125;); Futures的addCallback方法通过传入ListenableFuture和FutureCallback（一般情况FutureCallback实现为内部类）来实现回调机制。 1234//com.google.common.util.concurrent.Futurespublic static &lt;V&gt; void addCallback(ListenableFuture&lt;V&gt; future, FutureCallback&lt;? super V&gt; callback) &#123; addCallback(future, callback, directExecutor());&#125; 在addCallback方法中，我们发现多了一个 directExecutor()方法，这里的 directExecutor()方法返回的是一个枚举类型的线程池，这样做的目的是提高性能，而线程池中的execute方法实质执行的是所的传入参数Runnable 的run方法，可以把这里的线程池看作一个”架子”。 123456789101112//创建一个单实例的线程 接口需要显著的性能开销 提高性能public static Executor directExecutor() &#123; return DirectExecutor.INSTANCE;&#125;/** See &#123;@link #directExecutor&#125; for behavioral notes. */private enum DirectExecutor implements Executor &#123; INSTANCE; @Override public void execute(Runnable command) &#123; command.run(); &#125;&#125; 在具体的addCallback方法中，首先判断FutureCallback是否为空，然后创建一个线程，这个线程的run方法中会获取到一个value值，这里的value值即为http请求的结果，然后将value值传入FutureCallback的onSuccess方法，然后我们就可以在onSuccess方法中执行业务逻辑了。这个线程是如何执行的呢？继续往下看，发现调用了ListenableFuture的addListener方法，将刚才创建的线程和上一步创建的枚举线程池传入。 123456789101112131415161718192021222324252627282930313233//增加回调 public static &lt;V&gt; void addCallback(final ListenableFuture&lt;V&gt; future, final FutureCallback&lt;? super V&gt; callback, Executor executor) &#123; Preconditions.checkNotNull(callback); //每一个future进来都会创建一个独立的线程运行 Runnable callbackListener = new Runnable() &#123; @Override public void run() &#123; final V value; try &#123; // TODO(user): (Before Guava release), validate that this // is the thing for IE. //这里是真正阻塞的地方，直到获取到请求结果 value = getUninterruptibly(future); &#125; catch (ExecutionException e) &#123; callback.onFailure(e.getCause()); return; &#125; catch (RuntimeException e) &#123; callback.onFailure(e); return; &#125; catch (Error e) &#123; callback.onFailure(e); return; &#125; //调用callback的onSuccess方法返回结果 callback.onSuccess(value); &#125; &#125;; //增加监听，其中executor只提供了一个架子的线程池 future.addListener(callbackListener, executor); &#125; 在addListener方法中，将待执行的任务和枚举型线程池加入ExecutionList中，ExecutionList的本质是一个链表，将这些任务链接起来。具体可参考下方代码注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Override public void addListener(Runnable listener, Executor exec) &#123; //将监听任务和线程池加入到执行列表中 executionList.add(listener, exec); //This allows us to only start up a thread waiting on the delegate future when the first listener is added. //When a listener is first added, we run a task that will wait for the delegate to finish, and when it is done will run the listeners. //这允许我们启动一个线程来等待future当第一个监听器被加入的时候 //当第一个监听器被加入，我们将启动一个任务等待future完成，一旦当前的future完成后将会执行监听器 //判断是否有监听器加入 if (hasListeners.compareAndSet(false, true)) &#123; //如果当前的future完成则立即执行监听列表中的监听器,执行完成后返回 if (delegate.isDone()) &#123; // If the delegate is already done, run the execution list // immediately on the current thread. //执行监听列表中的监听任务 executionList.execute(); return; &#125; //如果当前的future没有完成，则启动线程池执行其中的任务，阻塞等待直到有一个future完成，然后执行监听器列表中的监听器 adapterExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; /* * Threads from our private pool are never interrupted. Threads * from a user-supplied executor might be, but... what can we do? * This is another reason to return a proper ListenableFuture * instead of using listenInPoolThread. */ getUninterruptibly(delegate); &#125; catch (Error e) &#123; throw e; &#125; catch (Throwable e) &#123; // ExecutionException / CancellationException / RuntimeException // The task is done, run the listeners. &#125; //执行链表中的任务 executionList.execute(); &#125; &#125;); &#125; &#125; &#125; 在ExecutionList的add方法中，判断是否执行完成，如果没有执行完成，则放入待执行的链表中并返回，否则调用executeListener方法执行任务，在executeListener方法中，我们发现执行的是线程池的execute方法，而execute方法实质的是调用了任务线程的run方法，这样最终会调用OnSuccess方法获取到执行结果。 12345678910111213141516171819202122232425//将任务放入ExecutionList中 public void add(Runnable runnable, Executor executor) &#123; // Fail fast on a null. We throw NPE here because the contract of // Executor states that it throws NPE on null listener, so we propagate // that contract up into the add method as well. Preconditions.checkNotNull(runnable, "Runnable was null."); Preconditions.checkNotNull(executor, "Executor was null."); // Lock while we check state. We must maintain the lock while adding the // new pair so that another thread can't run the list out from under us. // We only add to the list if we have not yet started execution. //判断是否执行完成，如果没有执行完成，则放入待执行的链表中 synchronized (this) &#123; if (!executed) &#123; runnables = new RunnableExecutorPair(runnable, executor, runnables); return; &#125; &#125; // Execute the runnable immediately. Because of scheduling this may end up // getting called before some of the previously added runnables, but we're // OK with that. If we want to change the contract to guarantee ordering // among runnables we'd have to modify the logic here to allow it. //执行监听 executeListener(runnable, executor); &#125; execute方法是执行任务链表中的任务，由于先加入的任务会依次排列在链表的末尾，所以需要将链表翻转。然后从链表头开始依次取出任务执行并放入枚举线程池中执行。 1234567891011121314151617181920212223242526272829303132333435363738394041//执行监听链表中的任务 public void execute() &#123; // Lock while we update our state so the add method above will finish adding // any listeners before we start to run them. //创建临时变量保存列表，并将成员变量置空让垃圾回收 RunnableExecutorPair list; synchronized (this) &#123; if (executed) &#123; return; &#125; executed = true; list = runnables; runnables = null; // allow GC to free listeners even if this stays around for a while. &#125; // If we succeeded then list holds all the runnables we to execute. The pairs in the stack are // in the opposite order from how they were added so we need to reverse the list to fulfill our // contract. // This is somewhat annoying, but turns out to be very fast in practice. Alternatively, we // could drop the contract on the method that enforces this queue like behavior since depending // on it is likely to be a bug anyway. // N.B. All writes to the list and the next pointers must have happened before the above // synchronized block, so we can iterate the list without the lock held here. //因为先加入的监听任务会在连边的末尾，所以需要将链表翻转 RunnableExecutorPair reversedList = null; while (list != null) &#123; RunnableExecutorPair tmp = list; list = list.next; tmp.next = reversedList; reversedList = tmp; &#125; //从链表头中依次取出监听任务执行 while (reversedList != null) &#123; executeListener(reversedList.runnable, reversedList.executor); reversedList = reversedList.next; &#125; &#125; 在上文中，可以发现每当对一个ListenerFuture增加回调时，都会创建一个线程，而这个线程的run方法中会获取一个value值，这个value值就是通过下面的getUninterruptibly方法获取到的，我们可以发现在方法中调用了while进行阻塞，一直等到future获取到结果，即发送的http请求获取到数据后才会终止并返回。可以看出，回调机制将获取结果中的阻塞分散开来，即使现在有100个线程在并发地发送http请求，那么也只是创建了100个独立的线程并行阻塞，那么运行的总时间则会是这100个线程中最长的时间，而不是100个线程的时间相加，这样就实现了异步非阻塞机制。 123456789101112131415161718//用while阻塞直到获取到结果 public static &lt;V&gt; V getUninterruptibly(Future&lt;V&gt; future) throws ExecutionException &#123; boolean interrupted = false; try &#123; while (true) &#123; try &#123; return future.get(); &#125; catch (InterruptedException e) &#123; interrupted = true; &#125; &#125; &#125; finally &#123; if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; 这里实质上执行了线程的run方法，并进行阻塞。 12345678910111213//执行监听器，调用线程池的execute方法，这里线程池并没有提供额外的功能，只提供了执行架子，实际上执行的是监听任务runnable的run方法 //而在监听任务的run方法中，会阻塞获取请求结果，请求完成后回调，已达到异步执行的效果 private static void executeListener(Runnable runnable, Executor executor) &#123; try &#123; executor.execute(runnable); &#125; catch (RuntimeException e) &#123; // Log it and keep going, bad runnable and/or executor. Don't // punish the other runnables if we're given a bad one. We only // catch RuntimeException because we want Errors to propagate up. log.log(Level.SEVERE, "RuntimeException while executing runnable " + runnable + " with executor " + executor, e); &#125; &#125; 使用JdkFutureAdaoter适配Spring中的ListenableFuture达到异步调用的结果。在future.get方法中到底阻塞在什么地方呢？通过调试发现最后调用的是BasicFuture中的阻塞方法。详情见下方源码和中文注释，这里不累赘。 123456FutureAdapter: //这里的get方法会调用BasicFuture中的get方法进行阻塞，直到获取到结果 @Override public T get() throws InterruptedException, ExecutionException &#123; return adaptInternal(this.adaptee.get()); &#125; 12345678BasicFuture: //在这里会判断当前future是否执行完成，如果没有完成则会等待，一旦执行完成则返回结果。 public synchronized T get() throws InterruptedException, ExecutionException &#123; while (!this.completed) &#123; wait(); &#125; return getResult(); &#125; 123456789101112131415161718192021222324252627282930313233FutureAdapter: //这里通过判断状态是否success，如果success则返回成功，如果new, 则阻塞等待结果直到返回，然后改变状态。 @SuppressWarnings("unchecked") final T adaptInternal(S adapteeResult) throws ExecutionException &#123; synchronized (this.mutex) &#123; switch (this.state) &#123; case SUCCESS: return (T) this.result; case FAILURE: throw (ExecutionException) this.result; case NEW: try &#123; T adapted = adapt(adapteeResult); this.result = adapted; this.state = State.SUCCESS; return adapted; &#125; catch (ExecutionException ex) &#123; this.result = ex; this.state = State.FAILURE; throw ex; &#125; catch (Throwable ex) &#123; ExecutionException execEx = new ExecutionException(ex); this.result = execEx; this.state = State.FAILURE; throw execEx; &#125; default: throw new IllegalStateException(); &#125; &#125; &#125; 123456789101112131415//这个方法判断 public boolean completed(final T result) &#123; synchronized(this) &#123; if (this.completed) &#123; return false; &#125; this.completed = true; this.result = result; notifyAll(); &#125; if (this.callback != null) &#123; this.callback.completed(result); &#125; return true; &#125; 总结本文主要剖析了Futures.callback方法的源码，我们只需要一个ListenableFuture的实例，就可以使用该方法来实现回调机制。假设在我们的主线程中，有n个子方法要发送http请求，这时，我们可以创建n个ListenableFuture，对这n个ListenableFuture增加监听，这n个请求就是异步且非阻塞的，这样不但主线程不会阻塞，而且会大大减少总的响应时间。那Futures.callback是如何实现并发的呢？通过源码，我们发现，对于每一个ListenableFuture，都会创建一个独立的线程对其进行监听，也就是这n个ListenableFuture对应着n个独立的线程，而在每一个独立的线程中会各自调用Future.get方法阻塞。]]></content>
      <categories>
        <category>网络通信</category>
      </categories>
      <tags>
        <tag>async</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己实现一个轻量级的任务（线程）管理器]]></title>
    <url>%2F2018%2F07%2F23%2Fepoch-taskmanager%2F</url>
    <content type="text"><![CDATA[功能 允许自定义任务（继承任务基类），比如实时任务，延时任务，周期任务等，实时任务和延时任务都是执行一次，周期任务会反复执行。 允许定义任务链，依次顺序执行，上游任务失败了下游任务不会执行。但是不提供下游任务失败了上游任务回滚的能力。 允许提交，暂停（非必须），继续，重做和取消任务。 允许根据多种方式查询任务，比如查询根据任务Id查询，根据条件查询等，获取任务状态，进度等信息。 允许自定义任务的回调函数（成功、取消，超时，失败的响应）。 支持任务的持久化（非必须）。 关键点1、什么时候保存任务的信息？ 任务第一次提交给任务管理器后，保存。任务成功或失败后，保存。 2、查询任务信息是每次都从后端查吗？ 任务创建后即加入到内存的容器中，在任务完成前都是从内存中查询，任务成功或者失败后（保存到数据库），从内存中删除任务的信息，而后的查询是从数据库查的。 3、当TaskManager退出时，应该扫描全部的任务，将内存中所有的任务（状态应该都是未完成）的快照都保存到数据库。以便于下次继续执行任务。 类结构设计1、Task 保存任务的静态信息，包括执行体（Callable），名称，类型，描述，参数，超时时间（可不设置）。 2、TaskTracker 保存任务的动态信息，包括进度，状态，运行时间等。]]></content>
      <categories>
        <category>调度管理</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架（二）之项目结构]]></title>
    <url>%2F2018%2F07%2F10%2Fepoch-rpc-2%2F</url>
    <content type="text"><![CDATA[前言 暂时还没法确定到底是什么样的包结构，等写完的时候再来填充这里。]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架（一）]]></title>
    <url>%2F2018%2F07%2F10%2Fepoch-rpc-1%2F</url>
    <content type="text"><![CDATA[前言 RPC的概念看过很多，我的理解是：调用端获取到服务（网络方法）提供者的网络地址，并把方法调用的参数通过网络传递给提供者，提供者监听并获取到参数后，调用自己的方法，再把执行结果通过网络回传给调用端。这样站在调用端的角度看，就像是调用自己的本地方法一样，只不过慢一些而已。 RPC经典的架构图如下： RPC架构中可以认为有四个角色，消费者（Consumer），提供者（Provider），注册中心（Registry）和监控中心（Monitor）。以前在同一系统里的方法调用者因为网络的存在，变成了消费者，被调的方法成为了提供者。而所谓的注册中心，其实就是为了让消费者实时的去感知提供者的存在，去告诉消费者它对应的提供者的地址。监控中心，其实在整个过程中，它并不是一定要存在，只是它可以做统计，做一些数据分析，提供整个系统的可用性，健壮性。 好了，我们先简单分析一下 Registry / Consumer / Provider / Monitor 这四个角色的定义和每个角色如何各司其职，相互协作完成这整个过程的。 下面从两个方面进行分析，一是每个角色在网络的定位，二是每个角色所要完成的职责。 Registry注册中心简述： 注册中心可以有多个，都是无状态的，每个注册中心之间信息不交互 从网络的角度来说，它都是server端，它不需要主动地连接其他的任何实例，只需要像一个地主一样等待别人来连接 消费者随机选择注册中心集群中的任何实例建立长连接，提供者与注册中心中的每一个实例都建立长连接 职责(与其说职责，还不如说代码要实现的功能)： 接收服务提供者的服务注册信息，接收到信息之后，发送ACK信息给服务提供者，否则服务提供者重新发送注册信息 接收消费者的订阅信息，并把它订阅的结果返回给消费者 如果注册信息变更，会主动通知订阅变更信息的消费者，注册信息的变更包括服务提供者下线，服务被人工降级，或者服务提供者的地址变更 持久化一些服务信息，例如某些服务管理员审核过了，则该服务重新注册后则不需要再审核，再例如，某个服务负载均衡的策略被管理员设置为轮询，那么下次它在注册的时候，则就是轮询，而不是默认的负载策略 Provider提供者简述： 提供者是一个精神分裂的病人，它在网络上（可以更加明确地说是站在Netty的角度上）饰演两个角色： 它是客户端，需要去连接Registry，发送注册信息，它也需要去连接monitor端，去发送一些调用的统计信息 它也是服务端，需要作为server端等待Consumer去连接，连接成功后调用服务 职责： 将自己的信息，提供的接口信息编织成注册信息发送给registry端 能够动态去调自己的方法，可以通过反射，cglib等一些方法去调用自己提供的那些方法 提供服务降级等服务，如果当某些服务调用的失败率高于限定值的时候，可以有一个对应的mock方法，提供降级服务 限流服务，限流的方式有很多种，也有很多实现方式，最简单的就是控制调用次数，比如100w次，其实简单的就是控制单位时间的调用次数，防止业务洪流冲垮服务 统计活动，将一些调用信息统计好发送给Monitor端 Consumer消费者简述： 它也是有两个网络角色，不过并不是精神分裂，它都是作为网络的客户端存在，一它需要去连接registry去获取到订阅信息，二是它需要主动去连接provider端去调用服务 职责： 去向Registry端订阅服务，拿到registry端返回的结果，这个结果也就是provider的网络地址，先建立TCP的长连接，可能是多个地址，因为提供某个服务的可能有多个提供者 当开始系统主动调用该服务的时候，拿到刚才建立的连接的集合，根据某个方法，是随意还是轮询，获取到其中的一个连接，发送方法入参，等待响应 当注册中心发送某个服务的调用的负载策略发生变化过，发送信息给consumer，consumer需要做相应的变更 Monitor监控者简述： 这个与整个系统是没有任何直接的关系的，实现方式也是多样的，可以与上面一样建立长连接，接收每个角色统计的信息，然后展示给用户，可以使用MQ,使用消息队列，每个角色把自己统计的信息放到队列中，Monitor去消费这些信息，这样做的好处就是解耦，如果monitor宕了，不影响服务 大体的RPC的流程稍微理了一下，接下来我们就来一一去实现这些功能~]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架]]></title>
    <url>%2F2018%2F07%2F05%2Fepoch-rpc-0%2F</url>
    <content type="text"><![CDATA[前言 RPC的文章看了不少，但是始终感觉似懂非懂，古人说的”纸上得来终觉浅，绝知此事要躬行”还是很有道理的。所以我希望通过一个真正的项目，来加深对RPC的认识。 这应该会是一个系列文章，至少在我动笔的这一刻是有非常强烈的意愿完成它的。 计划（暂定） 2018-07-08 架构设计，功能（细节）设计 2018-07-15 网络传输模型，序列化部分 2018-07-22 服务端框架 2018-07-29 客户端框架 2018-08-06 负载均衡 2018-08-13 服务降级 2018-08-20 测试与优化]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用操作记录]]></title>
    <url>%2F2018%2F07%2F05%2Fgit-operation%2F</url>
    <content type="text"><![CDATA[将本地仓库和github仓库关联起来 12git remote add github git@github.com:liningrui/study-rpc.gitgit pull 再查看所有分支就可以看到github远端分支的信息了 1git branch -av 删除github远端的分支 1git push github :travis 这样就删除了travis分支 创建orphan分支，名为source 1git checkout --orphan source 注：如果不提交东西，这个分支实际上没有创建]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2018%2F07%2F05%2Fjava-singleton%2F</url>
    <content type="text"><![CDATA[前言 在GoF的23种设计模式中，单例模式是比较简单的一种。然而，有时候越是简单的东西越容易出现问题。下面就单例设计模式详细的探讨一下。 所谓单例模式，简单来说，就是在整个应用中保证类只有一个实例存在。这个类的实例只提供了一个全局变量，用处相当广泛，比如保存全局数据，实现全局性的操作等。 最简单的实现首先，能够想到的最简单的实现是，把类的构造函数写成private的，从而保证别的类不能实例化此类，然后在类中提供一个静态的实例并能够返回给使用者。这样，使用者就可以通过这个引用使用到这个类的实例了。 123456789101112public class SingletonClass &#123; private static SingletonClass instance = new SingletonClass(); public static SingletonClass getInstance() &#123; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 外部使用者如果需要使用SingletonClass的实例，只能通过getInstance()方法，并且它的构造方法是private的，这样就保证了只能有一个对象存在。 性能优化上面的代码虽然简单，但是有一个问题—-无论这个类是否被使用，都会创建一个instance对象。如果这个创建过程很耗时，比如需要连接10000次jdbc实例连接或者10000多个模版实例，并且这个类还并不一定会被使用，那么这个创建过程就是无用的。 为了解决这个问题，我们想到了新的解决方案： 123456789101112131415public class SingletonClass &#123; private static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 代码的变化有一处—-把instance初始化为null，直到第一次使用的时候通过判断是否为null来创建对象。 我们来想象一下这个过程。要使用SingletonClass，调用getInstance()方法。第一次的时候发现instance是null，然后就新建一个对象，返回出去；第二次再使用的时候，因为这个instance是static的，所以已经不是null了，因此不会再创建对象，直接将其返回。 这个过程就称为lazy loaded，也就是延迟加载—-直到使用的时候才进行加载。 同步上面的代码很清楚，也很简单。然而就像那句名言：”80%的错误都是由20%代码优化引起的”。单线程下，这段代码没有什么问题，可是如果是多线程，麻烦就来了。我们来分析一下： 线程1希望使用SingletonClass，调用getInstance()方法。因为是第一次调用，1就发现instance是null的，于是它开始创建实例，就在这个时候，CPU发生时间片切换(或者被抢夺执行)，线程2开始执行，它要使用SingletonClass，调用getInstance()方法，同样检测到instance是null—-注意，这是在1检测完之后切换的，也就是说1并没有来得及创建对象—-因此2开始创建。2创建完成后，cpu切换到1继续执行，因为它已经检测完了，所以1不会再检测一遍，它会直接创建对象。这样，线程1和2各自拥有一个SingletonClass的对象—-单例失败！解决的方法也很简单，那就是加锁： 12345678910111213141516public class SingletonClass &#123; private static SingletonClass instance = null; public synchronized static SingletonClass getInstance() &#123; if(instance == null) &#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 又是性能问题上面的代码又是很清楚很简单的，然而，简单的东西往往不够理想。理想的东西往往不够简单，这就是生活。这段代码毫无疑问存在性能的问题—-synchronized修饰的同步块可是要比一般的代码段慢上几倍的！如果存在很多次getInstance()的调用，那性能问题就不得不考虑了！ 让我们来分析一下，究竟是整个方法都必须加锁，还是仅仅其中某一句加锁就足够了？我们为什么要加锁呢？分析一下出现lazy loaded的那种情形的原因。原因就是检测null的操作和创建对象的操作分离了。如果这两个操作能够原子地进行，那么单例就已经保证了。于是，我们开始修改代码： 1234567891011121314151617181920public class SingletonClass &#123; private static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; synchronized (SingletonClass.class) &#123; if (instance == null) &#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 还有问题吗？首先判断instance是不是为null，如果为null，加锁初始化；如果不为null，直接返回instance。 这就是double-checked locking设计实现单例模式。但是还有问题。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 下面来想一下，创建一个变量需要哪些步骤呢？一个是申请一块内存，调用构造方法进行初始化操作，另一个是分配一个指针指向这块内存。这两个操作谁在前谁在后呢？JMM规范并没有规定。（可能重排序）那么就存在这么一种情况，JVM是先开辟出一块内存，然后把指针指向这块内存，最后调用构造方法进行初始化。 线程1开始创建SingletonClass的实例，此时线程B调用了getInstance()方法，首先判断instance是否为null。按照我们上面所说的内存模型，1已经把instance指向了那块内存，只是还没有调用构造方法，因此2检测到instance不为null，于是直接把instance返回了—-问题出现了，尽管instance不为null，但它并没有构造完成，就像一套房子已经给了你钥匙，但你并不能住进去，因为里面还是毛坯房。此时，如果2在1将instance构造完成之前就是用了这个实例，程序就会出现错误了！ 最终解决方案在JDK 5之后，Java使用了新的内存模型。volatile关键字有了明确的语义—-在JDK1.5之前，volatile是个关键字，但是并没有明确的规定其用途—-被volatile修饰的写变量不能和之前的读写代码调整，读变量不能和之后的读写代码调整！因此，只要我们简单的把instance加上volatile关键字就可以了。 1234567891011121314151617181920public class SingletonClass &#123; private volatile static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; synchronized (SingletonClass.class) &#123; if(instance == null) &#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125;]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 下安装 jekyll]]></title>
    <url>%2F2018%2F07%2F04%2Fmac-install-jekyll%2F</url>
    <content type="text"><![CDATA[Mac 下安装 jekyll1sudo gem install jekyll 输入密码，但还是会提示没有写权限 12ERROR: While executing gem ... (Gem::FilePermissionError) You don&apos;t have write permissions for the /usr/bin directory. 原因是 Apple在OS X El Capitan中全面启用了名为System Integrity Protection (SIP)的系统完整性保护技术。受此影响，大部分系统文件即使在root用户下也无法直接进行修改。 升级ruby（推荐） 安装RVM1curl -L get.rvm.io | bash -s stable 出现异常 12345678910111213141516171819gpg: Signature made 一 7/ 2 03:41:26 2018 CSTgpg: using RSA key 62C9E5F4DA300D94AC36166BE206C29FBF04FF17gpg: Can&apos;t check signature: No public keyWarning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures).GPG signature verification failed for &apos;/Users/liningrui/.rvm/archives/rvm-1.29.4.tgz&apos; - &apos;https://github.com/rvm/rvm/releases/download/1.29.4/1.29.4.tar.gz.asc&apos;! Try to install GPG v2 and then fetch the public key: gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -the key can be compared with: https://rvm.io/mpapis.asc https://keybase.io/mpapisNOTE: GPG version 2.1.17 have a bug which cause failures during fetching keys from remote server. Please downgrade or upgrade to newer version (if available) or use the second method described above. 你是因为我本地安装了gpg，但是却没有它的公钥，所以我们需要先接受公钥到本地。 1gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 然后再执行上述命令，就应该Ok了。 1234567891011121314151617gpg: Signature made 一 7/ 2 03:41:26 2018 CSTgpg: using RSA key 62C9E5F4DA300D94AC36166BE206C29FBF04FF17gpg: Good signature from &quot;Michal Papis (RVM signing) &lt;mpapis@gmail.com&gt;&quot; [unknown]gpg: aka &quot;Michal Papis &lt;michal.papis@toptal.com&gt;&quot; [unknown]gpg: aka &quot;[jpeg image of size 5015]&quot; [unknown]gpg: WARNING: This key is not certified with a trusted signature!gpg: There is no indication that the signature belongs to the owner.Primary key fingerprint: 409B 6B17 96C2 7546 2A17 0311 3804 BB82 D39D C0E3 Subkey fingerprint: 62C9 E5F4 DA30 0D94 AC36 166B E206 C29F BF04 FF17GPG verified &apos;/Users/liningrui/.rvm/archives/rvm-1.29.4.tgz&apos;Installing RVM to /Users/liningrui/.rvm/ Adding rvm PATH line to /Users/liningrui/.profile /Users/liningrui/.mkshrc /Users/liningrui/.bashrc /Users/liningrui/.zshrc. Adding rvm loading line to /Users/liningrui/.profile /Users/liningrui/.bash_profile /Users/liningrui/.zlogin.Installation of RVM in /Users/liningrui/.rvm/ is almost complete: * To start using RVM you need to run `source /Users/liningrui/.rvm/scripts/rvm` in all your open shell windows, in rare cases you need to reopen all shell windows. 它提示说要使用RVM需要将rvm添加到环境变量中。 12source /Users/liningrui/.rvm/scripts/rvmrvm -v 列出所有可用的ruby版本 1rvm list known 安装最新版本的ruby（以2.5.1为例） 1rvm install 2.5.1 安装jekyll1gem install jekyll 安装完成后，cd到项目根目录，使用以下命令即可运行jekyll环境，通过 localhost:4000 即可访问。 1jekyll serve 提示1Dependency Error: Yikes! It looks like you don&apos;t have jekyll-paginate or one of its dependencies installed. In order to use Jekyll as currently configured, you&apos;ll need to install this gem. The full error message from Ruby is: &apos;cannot load such file -- jekyll-paginate&apos; If you run into trouble, you can find helpful resources at https://jekyllrb.com/help/! 安装即可 1gem install jekyll-paginate 接下来就可以开始github pages之路了～ 参考： https://www.cnblogs.com/kaiye/archive/2013/04/24/3039345.html https://blog.csdn.net/andanlan/article/details/50061775]]></content>
  </entry>
  <entry>
    <title><![CDATA[阻塞非阻塞与同步异步的区别]]></title>
    <url>%2F2018%2F07%2F04%2Fnetwork-io%2F</url>
    <content type="text"><![CDATA[我认为同步、异步、阻塞、非阻塞，是分3个层次的： CPU层次； 线程层次； 程序员感知层次。 这几个概念之所以容易混淆，是因为没有分清楚是在哪个层次进行讨论。 CPU层次在CPU层次，或者说操作系统进行IO和任务调度的层次，现代操作系统通常使用异步非阻塞方式进行IO（有少部分IO可能会使用同步非阻塞轮询），即发出IO请求之后，并不等待IO操作完成，而是继续执行下面的指令（非阻塞），IO操作和CPU指令互不干扰（异步），最后通过中断的方式来通知IO操作完成结果。 线程层次在线程层次，或者说操作系统调度单元的层次，操作系统为了减轻程序员的思考负担，将底层的异步非阻塞的IO方式进行封装，把相关系统调用（如read，write等）以同步的方式展现出来。然而，同步阻塞的IO会使线程挂起，同步非阻塞的IO会消耗CPU资源在轮询上。为了解决这一问题，就有3种思路： 多线程（同步阻塞）； IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）； 直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。 程序员感知层次在Linux中，上面提到的第2种思路用得比较广泛，也是比较理想的解决方案。然而，直接使用select之类的接口，依然比较复杂，所以各种库和框架百花齐放，都试图对IO多路复用进行封装。此时，库和框架提供的API又可以选择是以同步的方式还是异步的方式来展现。如python的asyncio库中，就通过协程，提供了同步阻塞式的API；如node.js中，就通过回调函数，提供了异步非阻塞式的API。 总结因此，我们在讨论同步、异步、阻塞、非阻塞时，必须先明确是在哪个层次进行讨论。比如node.js，我们可以说她在程序员感知层次提供了异步非阻塞的API，也可以说在Linux下，她在线程层次以同步非阻塞的epoll来实现。]]></content>
      <categories>
        <category>网络通信</category>
      </categories>
      <tags>
        <tag>NIO，IO</tag>
      </tags>
  </entry>
</search>
